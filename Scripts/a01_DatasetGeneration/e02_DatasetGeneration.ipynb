{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Generación del Dataset Variado\n",
    "Este Jupyter Notebook tiene como objetivo crear un dataset que contenga imágenes variadas de diferentes clases, teniendo en cuenta las columnas 'rev', 'station', 'season' y 'day_part' para garantizar la diversidad de las muestras.\n",
    "\n",
    "El archivo de entrada es un CSV que contiene información sobre las imágenes, incluyendo la ruta ('path'), la clase ('class'), la revisión ('rev'), la estación ('station'), la cámara ('cam'), la estación del año ('season'), el periodo del día ('day_part') y la fecha y hora ('date_time').\n",
    "\n",
    "Se excluyen algunas clases específicas, como 'unknown', 'cervid', 'other', 'leporid', 'invertebrate', 'multispecies' y 'small mammal', del dataset final.\n",
    "\n",
    "El flujo de trabajo es el siguiente:\n",
    "\n",
    "1. Se lee el archivo CSV utilizando pd.read_csv().\n",
    "2. Se filtran las filas excluyendo las clases especificadas utilizando ~df['class'].isin(excluded_classes).\n",
    "3. Se cuenta el número de imágenes por clase.\n",
    "4. Se define el número máximo de imágenes a tomar por clase.\n",
    "5. Se crea un DataFrame vacío para almacenar el dataset final.\n",
    "6. Se itera por cada clase y se realiza lo siguiente:\n",
    "7. Se obtienen las imágenes de la clase actual.\n",
    "8. Se determina la cantidad de imágenes a tomar de esta clase.\n",
    "9. Se agrupa el DataFrame por 'rev', 'station', 'season' y 'day_part'.\n",
    "10. Se toma una muestra aleatoria de cada grupo utilizando grouped.apply(lambda x: x.sample(n=min(num_images, len(x)), random_state=42)).\n",
    "11. Se restablece el índice del DataFrame de muestras aleatorias.\n",
    "12. Se agregan las imágenes al dataset final utilizando pd.concat().\n",
    "13. Se guarda el dataset final en un nuevo archivo CSV utilizando df_dataset.to_csv().\n",
    "14. El resultado es un dataset diverso y equilibrado, donde se tomarán hasta 1000 imágenes de cada clase, garantizando la variabilidad en las columnas 'rev', 'station', 'season' y 'day_part'.\n",
    "\n",
    "Recuerda especificar la ruta de salida adecuada para guardar el archivo CSV generado."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:47.748671500Z",
     "start_time": "2023-07-10T09:53:47.493520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Constantes\n",
    "\n",
    "# Ruta de los archivos CSV\n",
    "csv_path = \"../../CSVs/d01_images_data_amplified.csv\"\n",
    "\n",
    "# Definir el número máximo de imágenes a tomar por clase\n",
    "max_images_per_class = 3000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:47.749677900Z",
     "start_time": "2023-07-10T09:53:47.516527900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Leer el CSVs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Leer el archivo CSV de entrada\n",
    "df  = pd.read_csv(csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:49.649628400Z",
     "start_time": "2023-07-10T09:53:47.531529500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Obtener las clases únicas del DataFrame\n",
    "classes = df[\"class\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:49.726637400Z",
     "start_time": "2023-07-10T09:53:49.651628800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Clases a excluir\n",
    "excluded_classes = ['unknown', 'cervid', 'other', 'leporid', 'invertebrate', 'multispecies', 'small mammal']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:49.767174300Z",
     "start_time": "2023-07-10T09:53:49.728636900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Filtrar las filas por clases excluidas\n",
    "df_filtered = df[~df['class'].isin(excluded_classes)]\n",
    "# Reiniciar los índices del DataFrame df_filtered\n",
    "df_filtered = df_filtered.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:49.959357900Z",
     "start_time": "2023-07-10T09:53:49.768169100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Agrupar por clase y contar el número de imágenes\n",
    "class_counts = df_filtered.groupby('class').size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:50.035376600Z",
     "start_time": "2023-07-10T09:53:49.961364600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Función para seleccionar las imágenes según los criterios\n",
    "def select_images(row):\n",
    "    count = row['count']\n",
    "    if count <= max_images_per_class:\n",
    "        selected_images = df_filtered[df_filtered['class'] == row.name]\n",
    "        return selected_images\n",
    "    else:\n",
    "        num_images = min(count, max_images_per_class)\n",
    "        proportions = {\n",
    "            'day_part': None,\n",
    "            'station': None,\n",
    "            'season': None,\n",
    "            'rev': None\n",
    "        }\n",
    "\n",
    "        # Calcular proporciones automáticamente según las categorías presentes\n",
    "        for key in proportions:\n",
    "            if key == 'season':\n",
    "                season_counts = df_filtered[df_filtered['class'] == row.name]['season'].value_counts()\n",
    "                seasons = season_counts.index.tolist()\n",
    "                num_seasons = len(seasons)\n",
    "                if num_seasons > 0:\n",
    "                    proportions[key] = {season: 1 / num_seasons for season in seasons}\n",
    "            elif key == 'day_part':\n",
    "                day_parts = df_filtered[df_filtered['class'] == row.name]['day_part'].unique()\n",
    "                num_day_parts = len(day_parts)\n",
    "                if num_day_parts > 0:\n",
    "                    proportions[key] = {day_part: 1 / num_day_parts for day_part in day_parts}\n",
    "            elif key == 'station':\n",
    "                stations = df_filtered[df_filtered['class'] == row.name]['station'].unique()\n",
    "                num_stations = len(stations)\n",
    "                if num_stations > 0:\n",
    "                    proportions[key] = {station: 1 / num_stations for station in stations}\n",
    "            elif key == 'rev':\n",
    "                revs = df_filtered[df_filtered['class'] == row.name]['rev'].unique()\n",
    "                num_revs = len(revs)\n",
    "                if num_revs > 0:\n",
    "                    proportions[key] = {rev: 1 / num_revs for rev in revs}\n",
    "\n",
    "        selected_images = []\n",
    "        for key, values in proportions.items():\n",
    "            if key == 'day_part':\n",
    "                day_part_counts = df_filtered[df_filtered['class'] == row.name]['day_part'].value_counts()\n",
    "                for day_part, proportion in values.items():\n",
    "                    part_images = int(proportion * num_images)\n",
    "                    if day_part in day_part_counts:\n",
    "                        part_count = day_part_counts[day_part]\n",
    "                        if part_count < part_images:\n",
    "                            selected_images.extend(df_filtered[(df_filtered['class'] == row.name) & (df_filtered['day_part'] == day_part)].index)\n",
    "                            num_images -= part_count\n",
    "                        else:\n",
    "                            sample = df_filtered[(df_filtered['class'] == row.name) & (df_filtered['day_part'] == day_part)].sample(n=part_images).index\n",
    "                            selected_images.extend(sample)\n",
    "                            num_images -= part_images\n",
    "            elif key == 'station':\n",
    "                station_counts = df_filtered[df_filtered['class'] == row.name]['station'].value_counts()\n",
    "                for station, proportion in values.items():\n",
    "                    part_images = int(proportion * num_images)\n",
    "                    if station in station_counts:\n",
    "                        part_count = station_counts[station]\n",
    "                        if part_count < part_images:\n",
    "                            selected_images.extend(df_filtered[(df_filtered['class'] == row.name) & (df_filtered['station'] == station)].index)\n",
    "                            num_images -= part_count\n",
    "                        else:\n",
    "                            sample = df_filtered[(df_filtered['class'] == row.name) & (df_filtered['station'] == station)].sample(n=part_images).index\n",
    "                            selected_images.extend(sample)\n",
    "                            num_images -= part_images\n",
    "            elif key == 'season':\n",
    "                season_counts = df_filtered[df_filtered['class'] == row.name]['season'].value_counts()\n",
    "                for season, proportion in values.items():\n",
    "                    part_images = int(proportion * num_images)\n",
    "                    if season in season_counts:\n",
    "                        part_count = season_counts[season]\n",
    "                        if part_count < part_images:\n",
    "                            selected_images.extend(df_filtered[(df_filtered['class'] == row.name) & (df_filtered['season'] == season)].index)\n",
    "                            num_images -= part_count\n",
    "                        else:\n",
    "                            sample = df_filtered[(df_filtered['class'] == row.name) & (df_filtered['season'] == season)].sample(n=part_images).index\n",
    "                            selected_images.extend(sample)\n",
    "                            num_images -= part_images\n",
    "            elif key == 'rev':\n",
    "                rev_counts = df_filtered[df_filtered['class'] == row.name]['rev'].value_counts()\n",
    "                for rev, proportion in values.items():\n",
    "                    part_images = int(proportion * num_images)\n",
    "                    if rev in rev_counts:\n",
    "                        part_count = rev_counts[rev]\n",
    "                        if part_count < part_images:\n",
    "                            selected_images.extend(df_filtered[(df_filtered['class'] == row.name) & (df_filtered['rev'] == rev)].index)\n",
    "                            num_images -= part_count\n",
    "                        else:\n",
    "                            sample = df_filtered[(df_filtered['class'] == row.name) & (df_filtered['rev'] == rev)].sample(n=part_images).index\n",
    "                            selected_images.extend(sample)\n",
    "                            num_images -= part_images\n",
    "\n",
    "        if num_images > 0:\n",
    "            remaining_images = df_filtered[df_filtered['class'] == row.name].drop(selected_images).index\n",
    "            selected_images.extend(remaining_images[:num_images])\n",
    "\n",
    "        return selected_images\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:53:50.083425900Z",
     "start_time": "2023-07-10T09:53:50.038380500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Aplicar la función de selección de imágenes a cada clase\n",
    "selected_indices = class_counts.to_frame(name='count').apply(select_images, axis=1).explode().values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:54:47.416634900Z",
     "start_time": "2023-07-10T09:53:50.071422700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "selected_df = df_filtered.reindex(selected_indices[8:len(selected_indices)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:54:47.468636100Z",
     "start_time": "2023-07-10T09:54:47.417640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de imágenes seleccionadas por clase:\n",
      "cow            3000\n",
      "empty          3000\n",
      "fallow deer    3000\n",
      "horse          3000\n",
      "human          3000\n",
      "red deer       3000\n",
      "red fox        3000\n",
      "wild boar      3000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el resumen de las imágenes seleccionadas por clase\n",
    "selected_images_summary = selected_df[\"class\"].value_counts().sort_index()\n",
    "print(\"Resumen de imágenes seleccionadas por clase:\")\n",
    "print(selected_images_summary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:54:47.476642Z",
     "start_time": "2023-07-10T09:54:47.464643Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Definir la ruta y el nombre del archivo de salida\n",
    "output_file = \"../../CSVs/dataset_ampliado_caltech.csv\"\n",
    "# Guardar el DataFrame filtrado en un nuevo archivo CSV\n",
    "selected_df.to_csv(output_file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:54:47.584212600Z",
     "start_time": "2023-07-10T09:54:47.478657400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Guardar el DataFrame en un nuevo archivo CSV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "df_dataset_output = selected_df[['path', 'class']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:54:47.599737800Z",
     "start_time": "2023-07-10T09:54:47.586210700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Definir la ruta y el nombre del archivo de salida\n",
    "output_file = \"../../CSVs/dataset_caltech.csv\"\n",
    "\n",
    "# Guardar el DataFrame filtrado en un nuevo archivo CSV\n",
    "df_dataset_output.to_csv(output_file, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T09:54:47.662740300Z",
     "start_time": "2023-07-10T09:54:47.602753Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
